{"cells":[{"cell_type":"markdown","metadata":{"id":"9l1KOEVQWsSQ"},"source":["# 빅데이터및AI (1324201-01) 실습  "]},{"cell_type":"markdown","metadata":{"id":"wADdIitqj7ri"},"source":["## YOLOv8을 활용한 전방차량 및 브레이크 등 상태 탐지  \n","#### 객체 탐지(Object Detection) 목적으로 학습된 YOLOv8 모델을 활용하여 전방차량 및 해당 차량의 브레이크 등 상태를 탐지하는 인공지능 모델 학습 실습  \n","#### [**참고 영상**](https://www.dropbox.com/s/l91e0fjazbww4af/brake_light_detection_demo.mp4)\n"]},{"cell_type":"markdown","metadata":{"id":"Wj34c_5piJJI"},"source":["## 데이터셋 다운로드  \n","\n","#### 공개 데이터셋 사이트 방문, (회원가입 및 )로그인 후 조교의 안내에 따라 아래 코드를 완성하여 데이터셋 다운로드 가능  \n","#### [**공개 데이터셋 링크**](https://universe.roboflow.com/kookmin-university-glfyz/state-of-vehicle-tail-lamp-detection)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBH8cWS_Z2U-"},"outputs":[],"source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"0f7yCIzBZ72NY1PgdahK\")\n","project = rf.workspace(\"kookmin-university-glfyz\").project(\"state-of-vehicle-tail-lamp-detection\")\n","dataset = project.version(2).download(\"yolov8\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ycOJRZi1rqqH"},"outputs":[],"source":["# 다운로드된 데이터셋 위치 이동\n","!mkdir datasets     # datasets 폴더 생성\n","!mv ./State-of-vehicle-tail-lamp-detection-2/ ./datasets/State-of-vehicle-tail-lamp-detection-2/    # 공개데이터셋 이동\n","!mv ./datasets/State-of-vehicle-tail-lamp-detection-2/data.yaml ./data.yaml             # 데이터셋 설정 파일 이동\n","!wget -O data.yaml https://www.dropbox.com/scl/fi/70tikgw5bzmlhpytz22mx/data.yaml?rlkey=v0w68v5dcu7i5ecoskwufa0kd&dl=0  # Train용 데이터셋 설정 파일 다운로드\n","!wget -O data_test.yaml https://www.dropbox.com/scl/fi/xyd8hyduo7ixbh7i8gys0/data_test.yaml?rlkey=rzsp5diditahj3rx3udcmq3d5&dl=0 # Test용 데이터셋 설정 파일 다운로드"]},{"cell_type":"markdown","metadata":{"id":"i0bhuLS1n2X9"},"source":["## 탐색적 자료 분석(EDA)"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","\n","# Check current path position\n","cur_path = os.getcwd()\n","print(cur_path)\n","\n","# Check folder and file list under current path position\n","print(os.listdir(cur_path))"],"metadata":{"id":"NAd_3lWakLBd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3awMPmXt4ys9"},"source":["### yaml 파일 확인"]},{"cell_type":"code","source":["import yaml\n","\n","yaml_path = os.path.join(cur_path, 'data.yaml')     # Train, Validation file\n","with open(yaml_path) as f:\n","    data_info = yaml.load(f, Loader=yaml.FullLoader)\n","\n","for key, item in data_info.items():\n","    print(key, ':', item)"],"metadata":{"id":"IKIdqAQ_6XwF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_yaml_path = os.path.join(cur_path, 'data_test.yaml')   # Test file\n","\n","with open(test_yaml_path) as f:\n","    test_data_info = yaml.load(f, Loader=yaml.FullLoader)\n","\n","for key, item in test_data_info.items():\n","    print(key, ':', item)"],"metadata":{"id":"rL_G_4IR645l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 입,출력 데이터 확인"],"metadata":{"id":"L7scr56m7-RL"}},{"cell_type":"code","source":["# Define the base position of data\n","DATA_DIR = os.path.join(cur_path, 'datasets', 'State-of-vehicle-tail-lamp-detection-2')\n","print(os.listdir(DATA_DIR))"],"metadata":{"id":"oNkdW4tKkc4_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the position of train, validation, and test data\n","TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n","VAL_DIR = os.path.join(DATA_DIR, 'valid')\n","TEST_DIR = os.path.join(DATA_DIR, 'test')\n","\n","print(\"Train Folder: \", os.listdir(TRAIN_DIR))\n","print(\"Vaidation Folder: \", os.listdir(VAL_DIR))\n","print(\"Test Folder: \", os.listdir(TEST_DIR))"],"metadata":{"id":"zexdM2RPklq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the train image\n","TRAIN_IMG_DIR = os.path.join(TRAIN_DIR, 'images')\n","os.listdir(TRAIN_IMG_DIR)[:2]"],"metadata":{"id":"VGKJzbeNk6fy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython import display     # blackbox image\n","\n","# Show the train image\n","# img_file = os.listdir(TRAIN_IMG_DIR)[0]\n","sample_img_file = 'qyDn2S51_jpg.rf.fe33a97cd3c8cda330bc13db135f84da.jpg'\n","img_file_path = os.path.join(TRAIN_IMG_DIR, sample_img_file)\n","print(img_file_path)\n","display.Image(os.path.join(TRAIN_IMG_DIR, sample_img_file), width=500)"],"metadata":{"id":"YBOFuDZlk6iX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the train label\n","TRAIN_LB_DIR = os.path.join(TRAIN_DIR, 'labels')\n","os.listdir(TRAIN_LB_DIR)[:2]"],"metadata":{"id":"mEfUqrb1k6k_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show the train label\n","file_name = os.path.splitext(sample_img_file)[0]\n","label_file = file_name+'.txt'\n","label_file_path = os.path.join(TRAIN_LB_DIR, label_file)\n","print(label_file_path)"],"metadata":{"id":"ZaYOfooPnfX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(label_file_path, 'r') as f:\n","    contents = f.readlines()\n","contents\n","# (label에서의 class) (0 : brake off, 1 : brake on), (bounding box의 중심점(x, y), box의 size(h, w)) -> 이미지의 해상도 비율에 맞게"],"metadata":{"id":"tCqKxYTUnfda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_label_info(contents):\n","    '''label(.txt) 정보를 한줄 씩 읽어온 리스트를 입력받아 상세 정보를 분할하여 출력하는 함수\n","    입력: contents (list), label(.txt) 파일을 readlines를 통해 얻은 리스트 형태의 정보\n","    출력: info (list), contents 각 줄에 담겨있는 정보를 (class, x, y, w, h)의 튜플형태로 분할하여 순차적으로 축적시킨 리스트\n","    '''\n","\n","    # tuple이나 array로 불러서 담아옴\n","    info = []\n","    ##### ▽ 코드 작성 ▽ #####\n","    info = contents\n","    for i, data in enumerate(contents):\n","        class_data = tuple(map(int, data[0]))\n","        feature_data = tuple(map(float, data[1:].split()))\n","        info[i] = class_data + feature_data\n","    ##### △ 코드 작성 △ #####\n","    return info"],"metadata":{"id":"kOhs7Q4KtEep"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"(Class, x_corrdinate, y_corrdinate, width, height)\", end='\\n\\n')\n","\n","get_label_info(contents)"],"metadata":{"id":"iE_50y18urfe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Reporting Point**\n","* Train, Validation, Test Image 개수\n","* Train **vs** Validation & Test Image 차이점 기술\n","* Train, Validation, Test Label 개수\n","* Train, Validation, Test Label 중 Class 개수\n","* (Optional) EDA를 통해 얻은 직관 및 데이터셋의 대한 고찰"],"metadata":{"id":"YRimgi2WwI7w"}},{"cell_type":"markdown","source":["## Label 시각화"],"metadata":{"id":"8vzF_iS3xPqN"}},{"cell_type":"markdown","source":["#### **Reporting Point**\n","* Image 위에 Label 정보 시각화\n","* Class 별 서로 다른 색상으로 정확한 Bounding Box 그리기\n","* 최소 3장 이상의 그림을 레포트에 포함시킬 것\n","* 필요 시 아래 `draw_bbox_train` 함수 참조"],"metadata":{"id":"A_MOSwkA5Tpu"}},{"cell_type":"code","source":["import cv2\n","from google.colab.patches import cv2_imshow\n","\n","def draw_bbox_train(img_file):\n","    '''이미지 파일명을 입력 받아 해당 이미지의 label(.txt) 정보를 바운딩박스 형태로 이미지 위에 시각화하여 보여주는 함수\n","    클래스 별 바운딩박스의 태두리 색상을 다르게 할 것\n","    입력: img_file (str), 이미지 파일명 (확장자 포함)\n","    출력: None\n","    '''\n","\n","    ##### ▽ 코드 작성 ▽ #####\n","    colors = [(0, 255, 255), (255, 255, 0)]\n","    tickness = 2 # 박스 선 굵기\n","\n","    img_path = os.path.join(TRAIN_IMG_DIR, img_file)\n","    img = cv2.imread(img_path)\n","    img_width, img_height = img.shape[:2]\n","\n","    file_name = os.path.splitext(img_file)[0]\n","    label_file = file_name + '.txt'\n","    label_file_path = os.path.join(TRAIN_LB_DIR, label_file)\n","\n","    with open(label_file_path, 'r') as f:\n","        contents = f.readlines()\n","        label_info = get_label_info(contents)\n","\n","    for box in label_info:\n","        class_idx = int(box[0])\n","        x, y, w, h = map(float, box[1:])\n","        print(box[1:])\n","        left = int(img_width * (x-(w/2)))\n","        top = int(img_height * (y-(h/2)))\n","        width = int(img_width * w)\n","        height = int(img_height * h)\n","\n","        cv2.rectangle(img, (left, top), (left + width, top + height), colors[class_idx], tickness)\n","\n","    cv2_imshow(img)\n","    ##### △ 코드 작성 △ #####\n","\n","\n","draw_bbox_train(sample_img_file)"],"metadata":{"id":"YZxPw6WLyRoX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","random_img_file = random.choice(os.listdir(TRAIN_IMG_DIR))\n","draw_bbox_train(random_img_file)"],"metadata":{"id":"hUFmgl6K4TDJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0sqX_3YUdUMM"},"source":["## 인공신경망 학습\n","### 저장경로 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TmYVTEqzamB2"},"outputs":[],"source":["# 학습결과 저장을 위해 구글 드라이브 연동 (본인 구글 드라이브에 저장됨)\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQCyBQlQby_V"},"outputs":[],"source":["print(os.getcwd())  # 현재위치 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4FKN2EtRbN_C"},"outputs":[],"source":["BASE_PATH = os.path.join(os.getcwd(), 'drive', 'MyDrive', 'bigdata-ai-2023')\n","\n","if not os.path.isdir(BASE_PATH):\n","    os.makedirs(BASE_PATH)  # 기본폴더가 없으면 생성\n","\n","%cd drive/MyDrive/bigdata-ai-2023"]},{"cell_type":"markdown","metadata":{"id":"w8G0g_QWoctp"},"source":["### YOLOv8  \n","[YOLOv8 상세 문서](https://docs.ultralytics.com/)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XAUljKosocTb"},"outputs":[],"source":["!pip install -q ultralytics\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zvLH2_7WrASi"},"outputs":[],"source":["# YOLOv8 객체탐지 예시\n","!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/zidane.jpg'"]},{"cell_type":"code","source":["# Install and update Ultralytics and Ray Tune packages\n","!pip install -U ultralytics \"ray[tune]\"\n","\n","# Optionally install W&B for logging\n","!pip install wandb\n","!wandb login"],"metadata":{"id":"RpoV7aPXsMsK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D-2NUw5AaMeF"},"source":["### 전이학습\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FzJFq08no4sK"},"outputs":[],"source":["from ultralytics import YOLO\n","from ray import tune\n","# Load a pretrained model\n","model = YOLO('yolov8n.pt')\n","\n","# Train the model\n","## you can customize the hyperparameters...\n","num_epoch = 50\n","num_patience = 50\n","input_size = 320\n","batch_size = 64\n","\n","\n","result_grid = model.tune(data='/content/data.yaml',\n","                         optimizer='Adam',\n","                         iterators=num_patience,\n","                         epochs=50,\n","                         use_ray=True)\n","\n","\n","\n","\n","# Load a pretrained model # weight를 입힘\n","# model = YOLO('/content/drive/MyDrive/bigdata-ai-2023/runs/detect/train_epoch_50_256/weights/best.pt')\n","\n","# # Train the model\n","# ## you can customize the hyperparameters...\n","# num_epoch = 50\n","# num_patience = 50   # epoch\n","# input_size = 320\n","# batch_size = 64\n","\n","# results = model.train(data=\"/content/data.yaml\",\n","#                       epochs=num_epoch,\n","#                       patience=num_patience,\n","#                       optimizer='RAdam',\n","#                       imgsz=input_size,\n","#                       batch=batch_size,\n","#                       freeze=10,\n","#                       lr0=1E-3\n","#                       )\n","# train_args={\"epochs\": 20, \"batch\": 2}\n","# trainable_with_cpu_gpu = tune.with_resources(trainable, {\"cpu\": 2, \"gpu\": 1})"]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Load a pretrained model\n","model = YOLO('yolov8n.pt')\n","\n","# Train the model\n","## you can customize the hyperparameters...\n","num_epoch = 50\n","num_patience = 20\n","input_size = 640\n","batch_size = 16\n","lr = 1E-3\n","\n","                      # lr0=0.0724,\n","                      # lrf=0.0307,\n","                      # momentum=0.8757,\n","                      # warmup_epochs=4.7728,\n","                      # warmup_momentum=0.7052,\n","                      # weight_decay=0.0005816,\n","                      # seed=999\n","\n","results = model.train(data=\"/content/data.yaml\",\n","                      epochs=num_epoch,\n","                      patience=num_patience,\n","                      optimizer='SGD',\n","                      imgsz=input_size,\n","                      batch=batch_size,\n","                      lr0=lr,\n","                      lrf=lr\n","                      )\n","#freeze=10"],"metadata":{"id":"s9hMAc9-TdoG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PaJHS9xfqEFJ"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from ultralytics import YOLO\n","\n","# pts = {'SGD':'./runs/detect/Optimizer_change/train_default_SGD/weights/best.pt',\n","#        'Adam':'./runs/detect/Optimizer_change/train_default_Adam/weights/best.pt',\n","#        'Adamax':'./runs/detect/Optimizer_change/train_default_Adamax/weights/best.pt',\n","#        'AdamW':'./runs/detect/Optimizer_change/train_default_AdamW/weights/best.pt',\n","#        'NAdam':'./runs/detect/Optimizer_change/train_default_NAdam/weights/best.pt',\n","#        'RAdam':'./runs/detect/Optimizer_change/train_default_RAdam/weights/best.pt',\n","#        'RMSProp':'./runs/detect/Optimizer_change/train_default_RMSProp/weights/best.pt'}\n","\n","# pts = {'SGD':'./runs/detect/Default_change/train_default_SGD/weights/best.pt',\n","#        'Adam':'./runs/detect/Default_change/train_default_Adam/weights/best.pt',\n","#        'Adamax':'./runs/detect/Default_change/train_default_Adamax/weights/best.pt',\n","#        'AdamW':'./runs/detect/Default_change/train_default_AdamW/weights/best.pt',\n","#        'NAdam':'./runs/detect/Default_change/train_default_NAdam/weights/best.pt',\n","#        'RAdam':'./runs/detect/Default_change/train_default_RAdam/weights/best.pt',\n","#        'RMSProp':'./runs/detect/Default_change/train_default_RMSProp/weights/best.pt'}\n","\n","\n","pts = {'train_16_01_001':'./runs/detect/Adamax_fine_tune/train_16_01_001/weights/best.pt',\n","       'train_16_0001_001':'./runs/detect/Adamax_fine_tune/train_16_0001_001/weights/best.pt',\n","       'train_16_0001_0001':'./runs/detect/Adamax_fine_tune/train_16_0001_0001/weights/best.pt',\n","       'train_16_001_0001':'./runs/detect/Adamax_fine_tune/train_16_001_0001/weights/best.pt',\n","       'train_16_01_01':'./runs/detect/Adamax_fine_tune/train_16_01_01/weights/best.pt',\n","       'train_16_001_001':'./runs/detect/Adamax_fine_tune/train_16_001_001/weights/best.pt',\n","       'train_16_01_0001':'./runs/detect/Adamax_fine_tune/train_16_01_0001/weights/best.pt',\n","       'train_32_100_001':'./runs/detect/Adamax_fine_tune/train_32_100_001/weights/best.pt',\n","       'train_32_300_001':'./runs/detect/Adamax_fine_tune/train_32_300_001/weights/best.pt',\n","       'train_0002_09' : './runs/detect/Adamax_fine_tune/train_0002_09/weights/best.pt'}\n","\n","val_map50_ls = [0. for i in range(len(pts))]\n","val_total_time_ls = [0. for i in range(len(pts))]\n","\n","map50_ls = [0. for i in range(len(pts))]\n","total_time_ls = [0. for i in range(len(pts))]\n","key_ls = [0. for i in range(len(pts))]\n","\n","i = 0\n","for key, ptpath in pts.items():\n","  val_model = YOLO(f\"{ptpath}\")  # load a custom model\n","  val_metric = val_model.val(data=\"/content/data.yaml\") # Validate the model\n","\n","  metric = val_model.val(data=\"/content/data_test.yaml\")\n","\n","  print(f\"==============================<Validation : {key}>==============================\")\n","  print(f\"mAP50: {val_metric.box.map50}\")\n","  print(f\"preprocess time: {val_metric.speed['preprocess']}\")\n","  print(f\"inference time: {val_metric.speed['inference']}\")\n","  print(f\"postprocess time: {val_metric.speed['postprocess']}\")\n","\n","  print(f\"==============================<Test : {key}>==============================\")\n","  print(f\"mAP50: {metric.box.map50}\")\n","  print(f\"preprocess time: {metric.speed['preprocess']}\")\n","  print(f\"inference time: {metric.speed['inference']}\")\n","  print(f\"postprocess time: {metric.speed['postprocess']}\")\n","  print(f\"==========================================================================\")\n","\n","  val_map50_ls[i] = val_metric.box.map50\n","  val_total_time_ls[i] = val_metric.speed['preprocess'] + val_metric.speed['inference'] + val_metric.speed['postprocess']\n","\n","  map50_ls[i] = metric.box.map50\n","  total_time_ls[i] = metric.speed['preprocess'] + metric.speed['inference'] + metric.speed['postprocess']\n","  key_ls[i] = key\n","  i += 1\n","\n","plt.figure(figsize=(20,5))\n","plt.subplot(1, 2, 1)\n","for j in range(len(map50_ls)):\n","  plt.plot(total_time_ls[j], map50_ls[j], 'o', label=key_ls[j])\n","  #plt.text(total_time_ls[j], map50_ls[j], key_ls[j])\n","\n","plt.title('Accuracy-Speed tradeoff(val)');\n","plt.xlabel('total_time'); plt.ylabel('map_50'); plt.grid(); plt.legend()\n","plt.show()\n","\n","plt.figure(figsize=(20,5))\n","plt.subplot(1, 2, 2)\n","for j in range(len(val_map50_ls)):\n","  plt.plot(val_total_time_ls[j], val_map50_ls[j], 'o', label=key_ls[j])\n","  #plt.text(val_total_time_ls[j], val_map50_ls[j], key_ls[j])\n","\n","plt.title('Accuracy-Speed tradeoff(test)');\n","plt.xlabel('total_time'); plt.ylabel('map_50'); plt.grid(); plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I5UeZKe7dayZ"},"outputs":[],"source":["test_metrics = model.val(data=\"/content/data_test.yaml\")  # no arguments needed, dataset and settings remembered"]},{"cell_type":"code","source":["print(f\"mAP50: {test_metrics.box.map50}\")\n","print(f\"preprocess time: {test_metrics.speed['preprocess']}\")\n","print(f\"inference time: {test_metrics.speed['inference']}\")\n","print(f\"postprocess time: {test_metrics.speed['postprocess']}\")"],"metadata":{"id":"oC6T3kPS88JM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"jjbScT1ZVTfI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Reporting Point**\n","* mAP50에 대하여 기술\n","* 최소 3개 이상의 서로 다른 모델 학습\n","* 3개 이상의 학습 모델의 Accuracy - Speed 트레이드오프 그래프 그리기\n"],"metadata":{"id":"_w96I5hJ9B2H"}},{"cell_type":"code","source":[],"metadata":{"id":"lzdHhh4C9E4b"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"private_outputs":true,"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}